{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###### Hidden Markov Models PRIVATE NOTEBOOK\n",
    "\n",
    "\n",
    "###### Contents in this notebook\n",
    "\n",
    "######  Hidden markov models learning\n",
    "\n",
    "- Computing counts from a corpus\n",
    "- From counts to probabilities: finding the parameters of initial, transition and emission probabilities.\n",
    "- Smoothing non seen events in avoid overfitting.\n",
    "\n",
    "######  Working with scores instead of probabilities\n",
    "\n",
    "- Rewritting probabilities with log probabilities. \n",
    "- Why do we want to work with log probabilities? Understand issues when computing a product of probabilities.\n",
    "- The `logsumexp` trick.\n",
    "\n",
    "######  The forward backward algorithm\n",
    "\n",
    "- Computing the probability of a sequence $P(X=x)$\n",
    "- Computing the probability of a stage given an input sequence $P(Y_i=x \\,\\vert\\, X=x)$. \n",
    "- Use this probabilities to do Posterior decoding. Evaluate posterior decoding in a problem.\n",
    "\n",
    "\n",
    "###### Computing the most likely hidden state sequence: The viterbi algorithm\n",
    "\n",
    "- How to compute $argmax_{y_1,\\dots,y_N \\in \\Lambda^N} P(Y_{1:N}=y_{1:N}\\,\\vert\\, X=x)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:43:59.622390Z",
     "start_time": "2020-04-21T14:43:59.607509Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:43:59.812888Z",
     "start_time": "2020-04-21T14:43:59.737609Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "import skseq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### classes used to store the sequences\n",
    "\n",
    "We will use\n",
    "\n",
    "- class ``Sequence          ----> skseq/sequences/sequence.py`` file\n",
    "- class ``LabelDictionary   ----> skseq/sequences/label_dictionary.py`` file\n",
    "- class ``SequenceList      ----> skseq/sequences/sequence_list.py`` file\n",
    "- class ``_SequenceIterator ----> skseq/sequences/sequence_list.py`` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting a Sequence Object\n",
    "\n",
    "\n",
    "Before we start with HMMs let us import a `Sequence` class that we can use to build our model.\n",
    "\n",
    "- The `Sequence` class is defined in ``skseq/sequences/sequence.py``. \n",
    "    - A `Sequence` in a supervised learning problem consist on a set of words and tags associated to words.\n",
    "    - For example ``w_1/t_1 w_2/t_2 w_3/t_3`` is a sequence of length 3 with words ``w_i`` and tags ``t_i``.\n",
    "    \n",
    "\n",
    "In order to instanciate a Sequence we essentially need a list of words and a list of tags of the same size.\n",
    "\n",
    "In order to do use memory efficiently we will not store strings for the words and tags. We will store integer values to represent words and tags.\n",
    "\n",
    "An instance of a `Sequence` object has 2 very important fields that store the input and output:\n",
    "\n",
    "- **.x** attribute: list of words (integer words)\n",
    "\n",
    "- **.y** attribute: list of tags (integer tags)\n",
    "\n",
    "Then we need to keep a mapping from integers to words and from integers to tags.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:44:01.519993Z",
     "start_time": "2020-04-21T14:44:01.506636Z"
    }
   },
   "outputs": [],
   "source": [
    "import skseq\n",
    "import skseq.sequences\n",
    "import skseq.readers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:44:01.716839Z",
     "start_time": "2020-04-21T14:44:01.703330Z"
    }
   },
   "outputs": [],
   "source": [
    "from skseq.sequences import sequence\n",
    "\n",
    "seq = skseq.sequences.sequence.Sequence(x=[1,3,2,4],\n",
    "                                        y=[0,2,1,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-19T17:44:33.024293Z",
     "start_time": "2020-04-19T17:44:33.011083Z"
    }
   },
   "source": [
    "Note that seq has a fancy print version (code in `def __repr__`) that makes the object be printed\n",
    "as `w_1/t_1 w_2/t_2 w_3/t_3` when we simply write `seq` in the terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:16.114537Z",
     "start_time": "2020-04-21T14:42:16.097766Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1/0 3/2 2/1 4/1 "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:16.291880Z",
     "start_time": "2020-04-21T14:42:16.278806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "skseq.sequences.sequence.Sequence"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code, as is written, can get any list as input and any list as output (as long as both have the same length) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:16.629215Z",
     "start_time": "2020-04-21T14:42:16.615452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "David/P was/0 happy/0 "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = skseq.sequences.sequence.Sequence(x=[\"David\",\"was\",\"happy\"],\n",
    "                                        y=[\"P\",\"0\",\"0\"])\n",
    "\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:16.808839Z",
     "start_time": "2020-04-21T14:42:16.795856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['David', 'was', 'happy']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:16.970033Z",
     "start_time": "2020-04-21T14:42:16.956929Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P', '0', '0']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a vocabulary and a SequenceList\n",
    "\n",
    "Given a training set with words and tags we want to build a SequenceList object definded in  ``skseq/sequences/sequence_list.py``.\n",
    "\n",
    "A  `SequenceList` is a class that is initialized using:\n",
    "\n",
    "- **dictionary for the words**\n",
    "- **a dictionary for the tags**\n",
    "- **an empty `seq_list` where the Sequences read from the data will be stored.**\n",
    "\n",
    "\n",
    "    class SequenceList(object):\n",
    "\n",
    "        def __init__(self, x_dict, y_dict):\n",
    "            self.x_dict = x_dict\n",
    "            self.y_dict = y_dict\n",
    "            self.seq_list = []\n",
    "\n",
    "\n",
    "Let us create 3 sequence list for train, test and validation.  \n",
    "\n",
    "We will use the conll dataset and the class  ``PostagCorpus``.\n",
    "The class has a method ``.read_sequence_list_conll`` that will return the **SequenceList** object we want\n",
    "\n",
    "\n",
    "\n",
    "    def read_sequence_list_conll(self, train_file,\n",
    "                                 mapping_file=(\"%s/en-ptb.map\"\n",
    "                                               % dirname(__file__)),\n",
    "                                 max_sent_len=100000,\n",
    "                                 max_nr_sent=100000):\n",
    "\n",
    "        # Build mapping of postags:\n",
    "        mapping = {}\n",
    "        if mapping_file is not None:\n",
    "            for line in open(mapping_file):\n",
    "                coarse, fine = line.strip().split(\"\\t\")\n",
    "                mapping[coarse.lower()] = fine.lower()\n",
    "\n",
    "        instance_list = self.read_conll_instances(train_file,\n",
    "                                                  max_sent_len,\n",
    "                                                  max_nr_sent,\n",
    "                                                  mapping)\n",
    "\n",
    "        seq_list = SequenceList(self.word_dict, self.tag_dict)\n",
    "\n",
    "        for sent_x, sent_y in instance_list:\n",
    "            seq_list.add_sequence(sent_x, sent_y,  self.word_dict, self.tag_dict)\n",
    "\n",
    "        return seq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:17.909927Z",
     "start_time": "2020-04-21T14:42:17.290048Z"
    }
   },
   "outputs": [],
   "source": [
    "import skseq.readers.pos_corpus\n",
    "corpus = skseq.readers.pos_corpus.PostagCorpus()\n",
    "\n",
    "data_path = \"../data/conll\"\n",
    "\n",
    "train_seq = corpus.read_sequence_list_conll(data_path + \"/train-02-21.conll\", \n",
    "                                            max_sent_len=100, max_nr_sent=5000)\n",
    "\n",
    "test_seq = corpus.read_sequence_list_conll(data_path + \"/test-23.conll\",\n",
    "                                           max_sent_len=100, max_nr_sent=1000)\n",
    "\n",
    "dev_seq = corpus.read_sequence_list_conll(data_path + \"/dev-22.conll\", \n",
    "                                          max_sent_len=100, max_nr_sent=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:17.924835Z",
     "start_time": "2020-04-21T14:42:17.911423Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "skseq.sequences.sequence.Sequence"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_seq[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:17.940432Z",
     "start_time": "2020-04-21T14:42:17.926859Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "skseq.sequences.sequence_list.SequenceList"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:17.956410Z",
     "start_time": "2020-04-21T14:42:17.942304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['x_dict', 'y_dict', 'seq_list'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:17.973694Z",
     "start_time": "2020-04-21T14:42:17.960100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16937, 12)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_seq.x_dict), len(train_seq.y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:18.137172Z",
     "start_time": "2020-04-21T14:42:18.123902Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['x_dict', 'y_dict', 'seq_list'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:18.305269Z",
     "start_time": "2020-04-21T14:42:18.291823Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16937, 12)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_seq.x_dict), len(test_seq.y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:18.486897Z",
     "start_time": "2020-04-21T14:42:18.473826Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:18.642648Z",
     "start_time": "2020-04-21T14:42:18.629392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['x', 'y'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first sentence\n",
    "train_seq[0].__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:18.822241Z",
     "start_time": "2020-04-21T14:42:18.809181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42/2 40/2 43/6 44/2 41/4 "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:19.004688Z",
     "start_time": "2020-04-21T14:42:18.991439Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['x_dict', 'y_dict', 'seq_list'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:19.183455Z",
     "start_time": "2020-04-21T14:42:19.169235Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adp': 0,\n",
       " 'det': 1,\n",
       " 'noun': 2,\n",
       " 'num': 3,\n",
       " '.': 4,\n",
       " 'prt': 5,\n",
       " 'verb': 6,\n",
       " 'conj': 7,\n",
       " 'adv': 8,\n",
       " 'pron': 9,\n",
       " 'adj': 10,\n",
       " 'x': 11}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set of possible tags Lambda\n",
    "# train_seq.y_dict is a dictionary of mappings from tag to integer id \n",
    "train_seq.y_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:19.339884Z",
     "start_time": "2020-04-21T14:42:19.326754Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16937"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of possible words\n",
    "len(train_seq.x_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:19.522489Z",
     "start_time": "2020-04-21T14:42:19.509081Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42/2 40/2 43/6 44/2 41/4 "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using our corpus ``sequencelist`` to map integers to words\n",
    "\n",
    "Sequences can use ``SequenceList`` objects to map word_ids and tag_ids to words and tags.\n",
    "\n",
    "All ``sequence`` objects have the **``.to_words``** method which allows us to print the words given a **``SequenceList``** object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:20.059287Z",
     "start_time": "2020-04-21T14:42:20.046256Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['x_dict', 'y_dict', 'seq_list'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:20.261996Z",
     "start_time": "2020-04-21T14:42:20.249460Z"
    }
   },
   "outputs": [],
   "source": [
    "sequence = train_seq[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:20.430935Z",
     "start_time": "2020-04-21T14:42:20.417880Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42/2 40/2 43/6 44/2 41/4 "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:20.611012Z",
     "start_time": "2020-04-21T14:42:20.597590Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ms./noun Haag/noun plays/verb Elianti/noun ./. '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence.to_words(sequence_list=train_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Hidden markov models\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:21.138558Z",
     "start_time": "2020-04-21T14:42:21.126066Z"
    }
   },
   "outputs": [],
   "source": [
    "import skseq.sequences.sequence as seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:21.307607Z",
     "start_time": "2020-04-21T14:42:21.295108Z"
    }
   },
   "outputs": [],
   "source": [
    "Sigma = [\"walk\", \"shop\", \"clean\", \"tennis\"]\n",
    "Lambda = [\"rainy\", \"sunny\"]\n",
    "\n",
    "sequence_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:21.467218Z",
     "start_time": "2020-04-21T14:42:21.452949Z"
    }
   },
   "outputs": [],
   "source": [
    "# walk/rainy walk/sunny shop/sunny clean/sunny \n",
    "# walk/rainy walk/rainy shop/rainy clean/sunny \n",
    "# walk/sunny shop/sunny shop/sunny clean/sunny \n",
    "\n",
    "s1 = seq.Sequence([\"walk\", \"walk\", \"shop\", \"clean\"],\n",
    "                  [\"rainy\", \"sunny\", \"sunny\", \"sunny\"])\n",
    "\n",
    "s2 = seq.Sequence([\"walk\", \"walk\", \"shop\", \"clean\"], \n",
    "                  [\"rainy\", \"rainy\", \"rainy\", \"sunny\"])\n",
    "\n",
    "s3 = seq.Sequence([\"walk\", \"shop\", \"shop\", \"clean\"], \n",
    "                  [\"sunny\", \"sunny\", \"sunny\", \"sunny\"])\n",
    "\n",
    "train_sequences = [s1, s2, s3];\n",
    "\n",
    "s1_t = seq.Sequence([\"walk\", \"walk\", \"shop\", \"clean\"], \n",
    "                    [\"rainy\", \"sunny\", \"sunny\", \"sunny\"])\n",
    "\n",
    "s2_t = seq.Sequence([\"clean\", \"walk\", \"tennis\", \"walk\"], \n",
    "                    [\"sunny\", \"sunny\", \"sunny\", \"sunny\"])\n",
    "\n",
    "test_sequences = [s1_t, s2_t];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:21.646627Z",
     "start_time": "2020-04-21T14:42:21.633263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "walk/rainy walk/sunny shop/sunny clean/sunny "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:22.241205Z",
     "start_time": "2020-04-21T14:42:22.228642Z"
    }
   },
   "outputs": [],
   "source": [
    "word_to_pos  = {\"walk\":0,  \"shop\":1, \"clean\":2, \"tennis\":3}\n",
    "state_to_pos = {\"rainy\":0, \"sunny\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:22.538358Z",
     "start_time": "2020-04-21T14:42:22.523148Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_initial_counts(initial_counts, seq, state_to_pos):    \n",
    "    \"\"\"\n",
    "    TODO: Fill in this function and remove the pass\n",
    "    \"\"\"\n",
    "\n",
    "    pass\n",
    "\n",
    "def update_transition_counts(transition_counts, seq, state_to_pos):\n",
    "    \"\"\"\n",
    "    TODO: Fill in this function and remove the pass\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def update_emission_counts(emission_counts, seq, state_to_pos, word_to_pos):\n",
    "    \"\"\"\n",
    "    TODO: Fill in this function and remove the pass\n",
    "    \"\"\"\n",
    "\n",
    "def update_final_counts(final_counts, seq, state_to_pos):\n",
    "    \"\"\"\n",
    "    TODO: Fill in this function and remove the pass\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Using the previous function we can train the emisssion, initial and transition probabilities by simply counting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:32.941908Z",
     "start_time": "2020-04-21T14:42:32.927933Z"
    }
   },
   "outputs": [],
   "source": [
    "def sufficient_statistics_hmm(sequences, state_to_pos, word_to_pos):\n",
    "    \n",
    "    n_states = len(state_to_pos)\n",
    "    n_words  = len(word_to_pos)\n",
    "    initial_counts      = np.zeros((n_states))\n",
    "    transition_counts   = np.zeros((n_states, n_states))\n",
    "    final_counts        = np.zeros((n_states))\n",
    "    emission_counts     = np.zeros((n_states, n_words))\n",
    "    \n",
    "    for seq in sequences:\n",
    "        update_initial_counts(initial_counts, seq, state_to_pos)\n",
    "        update_transition_counts(transition_counts, seq,  state_to_pos)\n",
    "        update_emission_counts(emission_counts, seq,  state_to_pos, word_to_pos) \n",
    "        update_final_counts(final_counts, seq,  state_to_pos) \n",
    "    \n",
    "    return initial_counts, transition_counts, final_counts, emission_counts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:35.261266Z",
     "start_time": "2020-04-21T14:42:35.248568Z"
    }
   },
   "outputs": [],
   "source": [
    "counts = sufficient_statistics_hmm(train_sequences, \n",
    "                                   state_to_pos,\n",
    "                                   word_to_pos);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:35.584452Z",
     "start_time": "2020-04-21T14:42:35.571774Z"
    }
   },
   "outputs": [],
   "source": [
    "initial_counts, transition_counts, final_counts, emission_counts = counts;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:35.945332Z",
     "start_time": "2020-04-21T14:42:35.932297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 1.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:36.192500Z",
     "start_time": "2020-04-21T14:42:36.179095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 0.],\n",
       "       [2., 5.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:36.376410Z",
     "start_time": "2020-04-21T14:42:36.363123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 3.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:37.082001Z",
     "start_time": "2020-04-21T14:42:37.068750Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3., 2.],\n",
       "       [1., 3.],\n",
       "       [0., 3.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emission_counts.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:37.274596Z",
     "start_time": "2020-04-21T14:42:37.261268Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'walk': 0, 'shop': 1, 'clean': 2, 'tennis': 3}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:37.477080Z",
     "start_time": "2020-04-21T14:42:37.464016Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rainy': 0, 'sunny': 1}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_to_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Checks HMM\n",
    "\n",
    "- Initial counts must sum to the number of sentences  $$ \\sum_{k=1}^K C_{\\text{init}}(c_k) = M$$\n",
    "\n",
    "- Transition counts and Final Counts should sum to the number of tokens: $$\\sum_{k,l=1}^K C_{\\text{trans}}(c_k,c_l)  + \\sum_{k=1}^K C_{\\text{final}}(c_k) = M \\cdot N$$\n",
    "\n",
    "- Emission counts must sum to the number of tokens\n",
    "$$\n",
    "\\sum_{j=1}^J \\sum_{k=1}^K C_{\\text{emiss}}(w_j,c_k) = M \\cdot N \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:38.115720Z",
     "start_time": "2020-04-21T14:42:38.102480Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M:\t 3 \n",
      "N:\t 4 \n",
      "M*N:\t 12\n"
     ]
    }
   ],
   "source": [
    "M = len(train_sequences)\n",
    "N = len(train_sequences[0].x)\n",
    "print(\"M:\\t\", M, \"\\nN:\\t\", N,\"\\nM*N:\\t\", M*N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:38.514240Z",
     "start_time": "2020-04-21T14:42:38.500717Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_counts sum:  3.0\n",
      "emission_counts sum:  12.0\n",
      "transition and final counts sum:  12.0\n"
     ]
    }
   ],
   "source": [
    "print(\"initial_counts sum: \", np.sum(initial_counts))\n",
    "print(\"emission_counts sum: \", np.sum(emission_counts))\n",
    "print(\"transition and final counts sum: \",\\\n",
    "       np.sum(transition_counts) + sum(final_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:38.725138Z",
     "start_time": "2020-04-21T14:42:38.711807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 1.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:38.903537Z",
     "start_time": "2020-04-21T14:42:38.890392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 0.],\n",
       "       [2., 5.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:39.083616Z",
     "start_time": "2020-04-21T14:42:39.070535Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 3.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:39.344465Z",
     "start_time": "2020-04-21T14:42:39.330862Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3., 1., 0., 0.],\n",
       "       [2., 3., 3., 0.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emission_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From counts to probabilities\n",
    "\n",
    "The following formulas specify how to find the parameters of the HMM:\n",
    "\n",
    "$$\n",
    "P_{\\text{init}}(c_k \\,\\vert\\, \\text{start}) = \\frac{C_{\\text{init}}(c_k)}{ \\sum_{k=1}^K\n",
    "C_{\\text{init}} (c_l)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P_{\\text{final}}(\\text{stop} \\,\\vert\\, c_l) = \\frac{C_{\\text{final}}(c_l) }\n",
    "{\\sum_{k=1}^K C_{\\text{trans}}(c_k,c_l) + C_{\\text{final}}(c_l)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P_{\\text{trans}}( c_k \\,\\vert\\, c_l) = \\frac{C_{\\text{trans}}(c_k, c_l) }\n",
    "{\\sum_{p=1}^K C_{\\text{trans}}(c_p,c_l) + C_{\\text{final}}(c_l)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P_{\\text{emiss}} (w_j \\,\\vert\\, c_k) = \\frac{C_{\\text{emiss}} (w_j, c_k) }{\\sum_{q=1}^J C_{\\text{emiss}}(w_q,c_k)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:40.762420Z",
     "start_time": "2020-04-21T14:42:40.746612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "initial_probs\n",
      "[0.66666667 0.33333333]\n",
      "\n",
      "transition_probs\n",
      "[[0.5   0.   ]\n",
      " [0.5   0.625]]\n",
      "\n",
      "final_probs\n",
      "[0.    0.375]\n",
      "\n",
      "emission_probs\n",
      "[[0.75  0.25 ]\n",
      " [0.25  0.375]\n",
      " [0.    0.375]\n",
      " [0.    0.   ]]\n"
     ]
    }
   ],
   "source": [
    "#initial_probs    = (initial_counts / np.sum(initial_counts))\n",
    "#transition_probs = transition_counts/(np.sum(transition_counts, 1, keepdims=True) + final_counts)\n",
    "#final_probs      = final_counts/(np.sum(transition_counts, 1, keepdims=True) + final_counts )\n",
    "#emission_probs   = emission_counts / np.sum(emission_counts, 1, keepdims=True)\n",
    "\n",
    "    \n",
    "initial_probs    = (initial_counts / np.sum(initial_counts))\n",
    "transition_probs = transition_counts/(np.sum(transition_counts,0) + final_counts)\n",
    "final_probs      = final_counts/(np.sum(transition_counts, 0) + final_counts )\n",
    "emission_probs   = emission_counts.T / np.sum(emission_counts, 1)\n",
    "\n",
    "print(\"\\ninitial_probs\")\n",
    "print(initial_probs)\n",
    "\n",
    "print(\"\\ntransition_probs\")\n",
    "print(transition_probs)\n",
    "\n",
    "print(\"\\nfinal_probs\")\n",
    "print(final_probs)\n",
    "\n",
    "print(\"\\nemission_probs\")\n",
    "print(emission_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:42.099045Z",
     "start_time": "2020-04-21T14:42:42.085763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'walk': 0, 'shop': 1, 'clean': 2, 'tennis': 3}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "OBSERVATION:\n",
    "\n",
    "**If we stack trainsition and final counts and normalize them we get\n",
    "a proper conditional probability distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:43.548709Z",
     "start_time": "2020-04-21T14:42:43.536368Z"
    }
   },
   "outputs": [],
   "source": [
    "transitions_with_final_counts = np.vstack((transition_counts,\n",
    "                                           final_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:44.000221Z",
     "start_time": "2020-04-21T14:42:43.986986Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 0.],\n",
       "       [2., 5.],\n",
       "       [0., 3.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transitions_with_final_counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:44.202874Z",
     "start_time": "2020-04-21T14:42:44.189440Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5  , 0.   ],\n",
       "       [0.5  , 0.625],\n",
       "       [0.   , 0.375]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transitions_with_final_counts/ np.sum(transitions_with_final_counts,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with scores \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:45.069488Z",
     "start_time": "2020-04-21T14:42:45.049247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7999098843442183\n",
      "9.45876378447825\n",
      "90.00004540096037\n",
      "inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidbuchaca1/anaconda3/envs/py3_7/lib/python3.6/site-packages/ipykernel_launcher.py:7: RuntimeWarning: overflow encountered in exp\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#a = np.random.rand([0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.10])\n",
    "a = np.array([0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.10])\n",
    "\n",
    "print(np.log(sum(np.exp(a))))\n",
    "print(np.log(sum(np.exp(10*a))))\n",
    "print(np.log(sum(np.exp(100*a))))\n",
    "print(np.log(sum(np.exp(1000*a))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:45.913818Z",
     "start_time": "2020-04-21T14:42:45.899184Z"
    }
   },
   "outputs": [],
   "source": [
    "def logzero():\n",
    "    return -np.inf\n",
    "\n",
    "\n",
    "def safe_log(x):\n",
    "    print(x)\n",
    "    if x == 0:\n",
    "        return logzero()\n",
    "    return np.log(x)\n",
    "\n",
    "\n",
    "def logsum_pair(logx, logy):\n",
    "    \"\"\"\n",
    "    Return log(x+y), avoiding arithmetic underflow/overflow.\n",
    "\n",
    "    logx: log(x)\n",
    "    logy: log(y)\n",
    "\n",
    "    Rationale:\n",
    "\n",
    "    x + y    = e^logx + e^logy\n",
    "             = e^logx (1 + e^(logy-logx))\n",
    "    log(x+y) = logx + log(1 + e^(logy-logx)) (1)\n",
    "\n",
    "    Likewise,\n",
    "    log(x+y) = logy + log(1 + e^(logx-logy)) (2)\n",
    "\n",
    "    The computation of the exponential overflows earlier and is less precise\n",
    "    for big values than for small values. Due to the presence of logy-logx\n",
    "    (resp. logx-logy), (1) is preferred when logx > logy and (2) is preferred\n",
    "    otherwise.\n",
    "    \"\"\"\n",
    "    if logx == logzero():\n",
    "        return logy\n",
    "    elif logx > logy:\n",
    "        return logx + np.log1p(np.exp(logy-logx))\n",
    "    else:\n",
    "        return logy + np.log1p(np.exp(logx-logy))\n",
    "\n",
    "\n",
    "def logsum(logv):\n",
    "    \"\"\"\n",
    "    Return log(v[0]+v[1]+...), avoiding arithmetic underflow/overflow.\n",
    "    \"\"\"\n",
    "    res = logzero()\n",
    "    for val in logv:\n",
    "        res = logsum_pair(res, val)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:46.915953Z",
     "start_time": "2020-04-21T14:42:46.900733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7999098843442183\n",
      "9.45876378447825\n",
      "90.00004540096037\n",
      "inf\n",
      "\n",
      "\n",
      "2.7999098843442183\n",
      "9.45876378447825\n",
      "90.00004540096037\n",
      "900.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidbuchaca1/anaconda3/envs/py3_7/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: overflow encountered in exp\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#a = np.random.rand([0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.10])\n",
    "a = np.array([0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.10])\n",
    "\n",
    "print(np.log(sum(np.exp(a))))\n",
    "print(np.log(sum(np.exp(10*a))))\n",
    "print(np.log(sum(np.exp(100*a))))\n",
    "print(np.log(sum(np.exp(1000*a))))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(logsum(a))\n",
    "print(logsum(10*a))\n",
    "print(logsum(100*a))\n",
    "print(logsum(1000*a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:47.321357Z",
     "start_time": "2020-04-21T14:42:47.305504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7999098843442183\n",
      "9.45876378447825\n",
      "90.00004540096037\n",
      "inf\n",
      "\n",
      "\n",
      "2.7999098843442183\n",
      "9.45876378447825\n",
      "90.00004540096037\n",
      "900.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidbuchaca1/anaconda3/envs/py3_7/lib/python3.6/site-packages/ipykernel_launcher.py:13: RuntimeWarning: overflow encountered in exp\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def logsumexp(vec):\n",
    "    c = np.max(vec)\n",
    "    return c + np.log(np.sum(np.exp(vec-c)))\n",
    "\n",
    "#a = np.random.rand([0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.10])\n",
    "a = np.array([0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.10])\n",
    "\n",
    "print(np.log(sum(np.exp(a))))\n",
    "print(np.log(sum(np.exp(10*a))))\n",
    "print(np.log(sum(np.exp(100*a))))\n",
    "print(np.log(sum(np.exp(1000*a))))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(logsumexp(a))\n",
    "print(logsumexp(10*a))\n",
    "print(logsumexp(100*a))\n",
    "print(logsumexp(1000*a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:47.996724Z",
     "start_time": "2020-04-21T14:42:47.984539Z"
    }
   },
   "outputs": [],
   "source": [
    "# How can we find this? probabilities will be between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:48.627504Z",
     "start_time": "2020-04-21T14:42:48.576640Z"
    }
   },
   "outputs": [],
   "source": [
    "class HMM(object):\n",
    "    \n",
    "    def __init__(self, word_to_pos={}, state_to_pos={}):\n",
    "        self.fitted = False\n",
    "        self.counts = {\"emission\": None, \"transition\":None, \"final\":None, \"initial\":None}\n",
    "        self.probs  = {\"emission\": None, \"transition\":None, \"final\":None, \"initial\":None}\n",
    "        self.scores = {\"emission\": None, \"transition\":None, \"final\":None, \"initial\":None}\n",
    "        self.decode = set([\"posterior\", \"viterbi\"])\n",
    "        self.word_to_pos  = word_to_pos\n",
    "        self.state_to_pos = state_to_pos\n",
    "        self.pos_to_word  = {v: k for k, v in word_to_pos.items()}\n",
    "        self.pos_to_state = {v: k for k, v in state_to_pos.items()}\n",
    "    \n",
    "        self.n_states     = len(state_to_pos)\n",
    "        self.n_words      = len(word_to_pos)\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, observation_lables: list, state_labels: list):\n",
    "        \"\"\"\n",
    "        Computes and saves: counts, probs, scores.\n",
    "        \"\"\"\n",
    "        if self.state_to_pos is None or self.word_to_pos is None:\n",
    "            print(\"Error state_to_pos or word_to_pos needed to be defined\")\n",
    "            return\n",
    "            \n",
    "        self.counts = self.sufficient_statistics_hmm(observation_lables, state_labels)       \n",
    "        self.probs  = self.compute_probs(self.counts)  \n",
    "        self.scores = self.compute_scores(self.probs)  \n",
    "        self.fitted = True\n",
    "        \n",
    "    def sufficient_statistics_hmm(self, observation_lables, state_labels):\n",
    "\n",
    "        state_to_pos, word_to_pos = self.state_to_pos, self.word_to_pos\n",
    "        \n",
    "        def update_initial_counts(initial_counts, seq_x, state_to_pos):\n",
    "            \"\"\"\n",
    "            TODO: Fill in this function and remove the pass\n",
    "            \"\"\"\n",
    "            pass\n",
    "\n",
    "            \n",
    "        def update_transition_counts(transition_counts, seq_y, state_to_pos):\n",
    "            \"\"\"\n",
    "            TODO: Fill in this function and remove the pass\n",
    "            \"\"\"\n",
    "            pass\n",
    "\n",
    "\n",
    "        def update_emission_counts(emission_counts, seq_x, seq_y, state_to_pos, word_to_pos):\n",
    "            \"\"\"\n",
    "            TODO: Fill in this function and remove the pass\n",
    "            \"\"\"\n",
    "            pass\n",
    "\n",
    "        def update_final_counts(final_counts, seq_y, state_to_pos):\n",
    "            \"\"\"\n",
    "            TODO: Fill in this function and remove the pass\n",
    "            \"\"\"\n",
    "            pass\n",
    "\n",
    "\n",
    "        n_states = len(state_to_pos)\n",
    "        n_words  = len(word_to_pos)\n",
    "        initial_counts      = np.zeros((n_states))\n",
    "        transition_counts   = np.zeros((n_states, n_states))\n",
    "        final_counts        = np.zeros((n_states))\n",
    "        emission_counts     = np.zeros((n_states, n_words))\n",
    "\n",
    "        for seq_x, seq_y in zip(observation_lables, state_labels):\n",
    "            update_initial_counts(initial_counts, seq_y, state_to_pos)\n",
    "            update_transition_counts(transition_counts, seq_y,  state_to_pos)\n",
    "            update_emission_counts(emission_counts, seq_x, seq_y, state_to_pos, word_to_pos) \n",
    "            update_final_counts(final_counts, seq_y,  state_to_pos) \n",
    "\n",
    "        return {\"emission\":   emission_counts, \n",
    "                \"transition\": transition_counts,\n",
    "                \"final\":      final_counts, \n",
    "                \"initial\":    initial_counts}\n",
    "    \n",
    "    def compute_probs(self, counts):\n",
    "        \n",
    "        initial_counts    = counts['initial']\n",
    "        transition_counts = counts['transition']\n",
    "        emission_counts   = counts['emission']\n",
    "        final_counts      = counts['final']\n",
    "\n",
    "        initial_probs    = (initial_counts / np.sum(initial_counts))\n",
    "        transition_probs = transition_counts/(np.sum(transition_counts,0) + final_counts)\n",
    "        final_probs      = final_counts/(np.sum(transition_counts, 0) + final_counts )\n",
    "        emission_probs   = (emission_counts.T / np.sum(emission_counts, 1)).T\n",
    "    \n",
    "        return {\"emission\":   emission_probs, \n",
    "                \"transition\": transition_probs,\n",
    "                \"final\":      final_probs, \n",
    "                \"initial\":    initial_probs}\n",
    "    \n",
    "    def compute_scores(self, probs):\n",
    "         return {\"emission\":   np.log(probs[\"emission\"]), \n",
    "                 \"transition\": np.log(probs[\"transition\"]),\n",
    "                 \"final\":      np.log(probs[\"final\"]), \n",
    "                 \"initial\":    np.log(probs[\"initial\"])}\n",
    "        \n",
    "    def forward_computations(self, x: list):\n",
    "        forward_x = None\n",
    "        return forward_x\n",
    "    \n",
    "    def backward_computations(self, x:list):\n",
    "        backward_x = None\n",
    "        return backward_x\n",
    "    \n",
    "    def log_forward_computations(self, x: list):\n",
    "        \"\"\"\n",
    "        Compute the log_forward computations\n",
    "\n",
    "        Assume there are S possible states and a sequence of length N.\n",
    "        This method will compute iteritavely the log_forward quantities.\n",
    "\n",
    "        * log_f is a S x N Array.\n",
    "        * log_f_x[:,i] will contain the forward quantities at position i.\n",
    "        * log_f_x[:,i] is a vector of size S.\n",
    "        \n",
    "        Returns\n",
    "        - log_f_x: Array of size K x N\n",
    "        \"\"\" \n",
    "        n_x = len(x)\n",
    "        \n",
    "        # log_f_x initialized to -Inf because log(0) = -Inf\n",
    "        log_f_x = np.zeros((self.n_states, n_x)) - np.Inf\n",
    "        x_emission_scores = np.array([hmm.scores['emission'][:, hmm.word_to_pos[w]] for w in x]).T\n",
    "        \n",
    "        log_f_x[:,0] = x_emission_scores[:, 0] + self.scores['initial']\n",
    "        \n",
    "        \"\"\"\n",
    "        TODO: Fill in this function and remove the pass\n",
    "        compute log_f_x, log_likelihood\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "        return log_f_x, log_likelihood\n",
    "    \n",
    "    \n",
    "    def log_backward_computations(self, x: list):\n",
    "        n_x = len(x)\n",
    "        \n",
    "        # log_f_x initialized to -Inf because log(0) = -Inf\n",
    "        log_b_x = np.zeros((self.n_states, n_x)) - np.Inf\n",
    "        x_emission_scores = np.array([hmm.scores['emission'][:, hmm.word_to_pos[w]] for w in x]).T\n",
    "        log_b_x[:,-1] = self.scores['final']\n",
    "\n",
    "        \"\"\"\n",
    "        TODO: Fill in this function and remove the pass\n",
    "        compute log_b_x, log_likelihood\n",
    "        \"\"\"\n",
    "        \n",
    "        return log_b_x, log_likelihood\n",
    "        \n",
    "    def predict_labels(self, x: list, decode=\"posterior\"):\n",
    "        \"\"\"\n",
    "        Retuns a sequence of states for each word in **x**.\n",
    "        The output depends on the **decode** method chosen.\n",
    "        \"\"\"\n",
    "        assert decode in self.decode, \"decode `{}` is not valid\".format(decode)\n",
    "        \n",
    "        if decode is 'posterior':\n",
    "            return self.posterior_decode(x)\n",
    "        \n",
    "        if decode is 'viterbi':\n",
    "            return self.viterbi_decode(x)\n",
    "\n",
    "    def compute_state_posteriors(self, x:list):\n",
    "        log_f_x, log_likelihood = self.log_forward_computations(x)\n",
    "        log_b_x, log_likelihood = self.log_backward_computations(x)\n",
    "        state_posteriors = np.zeros((self.n_states, len(x)))\n",
    "        \n",
    "        for pos in range(len(x)):\n",
    "            state_posteriors[:, pos] = log_f_x[:, pos] + log_b_x[:, pos] - log_likelihood\n",
    "        return state_posteriors\n",
    "\n",
    "    def posterior_decode(self, x: list, decode_states=True):\n",
    "        \n",
    "        state_posteriors = self.compute_state_posteriors(x)\n",
    "        y_hat = state_posteriors.argmax(axis=0)\n",
    "        \n",
    "        if decode_states:\n",
    "            y_hat = [hmm.pos_to_state[y] for y in y_hat]\n",
    "            \n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:54.529825Z",
     "start_time": "2020-04-21T14:42:54.516622Z"
    }
   },
   "outputs": [],
   "source": [
    "hmm = HMM(word_to_pos, state_to_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:54.847120Z",
     "start_time": "2020-04-21T14:42:54.833559Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'rainy': 0, 'sunny': 1}, {'walk': 0, 'shop': 1, 'clean': 2, 'tennis': 3})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.state_to_pos, hmm.word_to_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:55.036348Z",
     "start_time": "2020-04-21T14:42:55.023696Z"
    }
   },
   "outputs": [],
   "source": [
    "X = [t.x for t in train_sequences]\n",
    "Y = [t.y for t in train_sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:55.238783Z",
     "start_time": "2020-04-21T14:42:55.225670Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidbuchaca1/anaconda3/envs/py3_7/lib/python3.6/site-packages/ipykernel_launcher.py:85: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/davidbuchaca1/anaconda3/envs/py3_7/lib/python3.6/site-packages/ipykernel_launcher.py:86: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/davidbuchaca1/anaconda3/envs/py3_7/lib/python3.6/site-packages/ipykernel_launcher.py:87: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "hmm = HMM(word_to_pos, state_to_pos)\n",
    "hmm.fit(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:55.453868Z",
     "start_time": "2020-04-21T14:42:55.439298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emission \n",
      " [[3. 1. 0. 0.]\n",
      " [2. 3. 3. 0.]] \n",
      "\n",
      "transition \n",
      " [[2. 0.]\n",
      " [2. 5.]] \n",
      "\n",
      "final \n",
      " [0. 3.] \n",
      "\n",
      "initial \n",
      " [2. 1.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in hmm.counts:\n",
    "    print(k,'\\n', hmm.counts[k],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:55.948269Z",
     "start_time": "2020-04-21T14:42:55.934390Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emission \n",
      " [[0.75  0.25  0.    0.   ]\n",
      " [0.25  0.375 0.375 0.   ]] \n",
      "\n",
      "transition \n",
      " [[0.5   0.   ]\n",
      " [0.5   0.625]] \n",
      "\n",
      "final \n",
      " [0.    0.375] \n",
      "\n",
      "initial \n",
      " [0.66666667 0.33333333] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in hmm.probs:\n",
    "    print(k,'\\n', hmm.probs[k],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:56.264343Z",
     "start_time": "2020-04-21T14:42:56.250628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emission \n",
      " [[-0.28768207 -1.38629436        -inf        -inf]\n",
      " [-1.38629436 -0.98082925 -0.98082925        -inf]] \n",
      "\n",
      "transition \n",
      " [[-0.69314718        -inf]\n",
      " [-0.69314718 -0.47000363]] \n",
      "\n",
      "final \n",
      " [       -inf -0.98082925] \n",
      "\n",
      "initial \n",
      " [-0.40546511 -1.09861229] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in hmm.scores:\n",
    "    print(k,'\\n', hmm.scores[k],'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Efficient forward probability computation\n",
    "\n",
    "The forward probability represents the probability that in position\n",
    "$i$ we are in state $Y_i = c_k$ and that we have observed $x_1,\\ldots,x_i$\n",
    "up to that position. Therefore, its mathematical expression is:\n",
    "\\begin{equation}\n",
    "\\mathbf{Forward \\ Probability\\!:}\\;\\;\\;\\;  \\mathrm{forward}(i, c_k) = P(Y_i = c_k, X_1=x_1,\\ldots, X_i = x_i)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Using the independence assumptions of the HMM we can compute $\\mathrm{forward}(i, c_k)$ using all the forward computations \\{$\\mathrm{forward}(i -1, c)$ for $c \\in \\Lambda$\\}. In order to facilitate the notation of the following argument we will denote by $x_{i:j}$  the assignemnt $X_i = x_i, \\dots, X_j = x_j$. Therefore we can write   $\\mathrm{forward}(i, y_i) $ as $P( y_i, x_{1:i } ) $ and rewrite the forward expression as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "  P( y_i, x_{1:i } ) =  \\sum_{y_{i-1} \\in \\Lambda} P( y_i ,y_{i-1}, x_{1:i } )  =  \\sum_{y_{i-1} \\in \\Lambda} P( x_i  | y_i,  y_{i-1},  x_{1:i-1 } ) \\cdot P(y_i  | y_{i-1},  x_{1:i-1 }) \\cdot P(y_{i-1},  x_{1:i-1 })  \n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Using the **Observation independence** and the **Independence of previous states** properties of the first order HMM we have $P( x_i  | y_i,  y_{i-1},  x_{1:i-1 } ) = P( x_i  | y_i) $ and $P(y_i  | y_{i-1},  x_{1:i-1 })  = P(y_i  | y_{i-1})  $. Therefore the previous equation can be written, \n",
    "for $i \\in \\{2,\\dots,N\\}$ (where $N$ is the length of the sequence), as \n",
    "\n",
    "\\begin{equation}\n",
    " \\mathrm{forward}(i, y_i)  = \\sum_{y_{i-1} \\in \\Lambda} P( x_i  | y_i, ) \\cdot P(y_i  | y_{i-1}) \\cdot \\mathrm{forward}(i-1, y_{i-1})   \n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "The previous equation proves that  the forward probability can be defined by the\n",
    "following recurrence rule: \n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\mathrm{forward}(1, c_k)&=& P_{\\text{init}}(c_k|\\text{start}) \\times P_{\\mathrm{emiss}}(x_1 | c_k)\n",
    " \\\\\n",
    " \\mathrm{forward}(i, c_k) &=& \\left(  \\sum_{c_l \\in \\Lambda} P_{\\mathrm{trans}}(c_k | c_l) \\times \\mathrm{forward}(i-1, c_l) \\right) \\times P_{\\mathrm{emiss}}(x_i | c_k) \n",
    " \\\\\n",
    "  \\mathrm{forward}(N+1, \\text{stop}) &=& \\sum_{c_l \\in \\Lambda} P_{\\text{final}}(\\text{ stop} | c_l) \\times \\mathrm{forward}(N, c_l).\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "Using the forward trellis one can compute the likelihood simply as:\n",
    "\n",
    "\\begin{equation}\n",
    "P(X=x) = \\mathrm{forward}(N+1, \\text{ stop}).\n",
    "\\end{equation}\n",
    "\n",
    "Although the forward probability is enough to calculate the likelihood of a given sequence, we will also need the backward probability to calculate the state posteriors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:57.690829Z",
     "start_time": "2020-04-21T14:42:57.677761Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['walk', 'walk', 'shop', 'clean']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = train_sequences[1].x\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:58.040009Z",
     "start_time": "2020-04-21T14:42:58.027365Z"
    }
   },
   "outputs": [],
   "source": [
    "log_forward, loglikelihood = hmm.log_forward_computations(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:58.236441Z",
     "start_time": "2020-04-21T14:42:58.222821Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.69314718, -1.67397643, -3.75341798,        -inf],\n",
       "       [-2.48490665, -2.58334672, -2.94017562, -4.08740307]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:58.422350Z",
     "start_time": "2020-04-21T14:42:58.408929Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.068232326005127"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loglikelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Efficient backward probability computation\n",
    "\n",
    "\n",
    "\n",
    "The backward probability is similar to the forward probability, but operates in the inverse direction.\n",
    "It represents the probability of observing $x_{i+1},\\ldots,x_N$ from position $i+1$ up to $N$, given that at position $i$ we are at state $Y_i = c_l$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{Backward \\ Probability\\!:}\\;\\;\\;\\;  \\text{backward}(i, c_l) = P(X_{i+1}=x_{i+1},\\ldots, X_N=x_N | Y_i = c_l).\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "Using the independence assumptions of the HMM we can compute $\\text{backward}(i, c_k)$ using all the backward computations $\\text{backward}(i +1, c)$ for $c \\in \\Lambda$.\n",
    "\n",
    "Therefore we can write   $\\text{backward}(i, y_i) $ as $P( x_{i+1:N} | y_i ) $ and rewrite the forward expression as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "  P( x_{i+1:N} | y_i ) =  \\sum_{y_{i+1} \\in \\Lambda} P( x_{i+1:N}, y_{i+1} | y_i)  =  \\sum_{y_{i+1} \\in \\Lambda} P( x_{i+2:N} | y_i, y_{i+1}, x_{i+1}) \n",
    "   P( x_{i+1}, |  y_{i+1},  y_{i}) P( y_{i+1} | y_i)\n",
    "\\end{equation}\n",
    "\n",
    "Using the previous equation we have proved that the backward probability can be defined by the following recurrence rule:\n",
    "\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\mathrm{backward}(N, c_l) &=& P_{\\text{final}}(\\text{stop} | c_l)  \\\\\n",
    "\\text{backward}(i, c_l) &=&  \\displaystyle \\sum_{c_k \\in \\Lambda} P_{\\text{trans}}(c_k | c_l) \\times \n",
    "\\text{backward}(i+1, c_k) \\times P_{\\text{emiss}}(x_{i+1} | c_k) \n",
    " \\\\\n",
    "  \\mathrm{backward}(0, \\text{start}) &=& \\sum_{c_k \\in \\Lambda} P_{\\mathrm{init}}(c_k | \\text{ start}) \\times \\mathrm{backward}(1, c_k) \\times P_{\\mathrm{emiss}}(x_{1} | c_k).\n",
    " \\end{eqnarray}\n",
    "\n",
    "Using the backward trellis one can compute the likelihood simply as:\n",
    "\n",
    "\\begin{equation}\n",
    "P(X=x) = \\mathrm{backward}(0, \\text{start}).\n",
    "\\end{equation}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:42:59.209862Z",
     "start_time": "2020-04-21T14:42:59.196481Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['walk', 'walk', 'shop', 'clean']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = train_sequences[1].x\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:43:00.357697Z",
     "start_time": "2020-04-21T14:43:00.344485Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_backward, loglikelihood_b = hmm.log_backward_computations(example)\n",
    "log_forward,  loglikelihood_f = hmm.log_forward_computations(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:43:00.582681Z",
     "start_time": "2020-04-21T14:43:00.569400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.068232326005126, -5.068232326005127)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loglikelihood_b, loglikelihood_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:43:00.773855Z",
     "start_time": "2020-04-21T14:43:00.760378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.41863845, -3.67819455, -2.65480569,        -inf],\n",
       "       [-5.73879301, -3.88249502, -2.43166214, -0.98082925]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:43:00.953038Z",
     "start_time": "2020-04-21T14:43:00.940525Z"
    }
   },
   "outputs": [],
   "source": [
    "state_pos = hmm.compute_state_posteriors(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:43:01.168024Z",
     "start_time": "2020-04-21T14:43:01.154645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_pos.argmax(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a HMM in the conll data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:43:02.569479Z",
     "start_time": "2020-04-21T14:43:02.134708Z"
    }
   },
   "outputs": [],
   "source": [
    "train_seq = corpus.read_sequence_list_conll(data_path + \"/train-02-21.conll\", \n",
    "                                            max_sent_len=100, max_nr_sent=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:43:02.586204Z",
     "start_time": "2020-04-21T14:43:02.571158Z"
    }
   },
   "outputs": [],
   "source": [
    "ind_to_word  = {v: k for k, v in train_seq.x_dict.items()}\n",
    "ind_to_state = {v: k for k, v in train_seq.y_dict.items()}\n",
    "word_to_ind  = train_seq.x_dict\n",
    "state_to_ind = train_seq.y_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:43:03.035424Z",
     "start_time": "2020-04-21T14:43:03.001885Z"
    }
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for i in range(len(train_seq)):\n",
    "    xy = train_seq[i]\n",
    "    X.append([ind_to_word[x_i] for x_i in xy.x])\n",
    "    Y.append([ind_to_state[y_i] for y_i in xy.y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:43:03.238057Z",
     "start_time": "2020-04-21T14:43:03.224771Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Ms.', 'Haag', 'plays', 'Elianti', '.'],\n",
       " ['noun', 'noun', 'verb', 'noun', '.'])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1],Y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:43:03.581182Z",
     "start_time": "2020-04-21T14:43:03.438210Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidbuchaca1/anaconda3/envs/py3_7/lib/python3.6/site-packages/ipykernel_launcher.py:85: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/davidbuchaca1/anaconda3/envs/py3_7/lib/python3.6/site-packages/ipykernel_launcher.py:86: RuntimeWarning: divide by zero encountered in log\n",
      "/Users/davidbuchaca1/anaconda3/envs/py3_7/lib/python3.6/site-packages/ipykernel_launcher.py:87: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "hmm = HMM(word_to_ind, state_to_ind)\n",
    "hmm.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:43:03.801104Z",
     "start_time": "2020-04-21T14:43:03.764581Z"
    }
   },
   "outputs": [],
   "source": [
    "y_hat = hmm.predict_labels(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to make a prediction\n",
    "\n",
    "use `hmm.predict_labels ` to get the set of part of speech tags for a given sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:43:05.097318Z",
     "start_time": "2020-04-21T14:43:05.061065Z"
    }
   },
   "outputs": [],
   "source": [
    "y_hat = hmm.predict_labels(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:43:05.262670Z",
     "start_time": "2020-04-21T14:43:05.249616Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In an Oct. 19 review of `` The Misanthrope '' at Chicago 's Goodman Theatre ( `` Revitalized Classics Take the Stage in Windy City , '' Leisure & Arts ) , the role of Celimene , played by Kim Cattrall , was mistakenly attributed to Christina Haag .\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:43:05.453688Z",
     "start_time": "2020-04-21T14:43:05.440833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adp det noun num noun adp . det noun . adp noun prt noun noun . . verb noun verb det noun adp noun noun . . noun conj noun . . det noun adp noun . verb adp noun noun . verb adv verb prt noun noun .'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:43:05.669036Z",
     "start_time": "2020-04-21T14:43:05.656409Z"
    }
   },
   "outputs": [],
   "source": [
    "result = skseq.sequences.sequence.Sequence(X[0],y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:43:05.851494Z",
     "start_time": "2020-04-21T14:43:05.838159Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In/adp an/det Oct./noun 19/num review/noun of/adp ``/. The/det Misanthrope/noun ''/. at/adp Chicago/noun 's/prt Goodman/noun Theatre/noun (/. ``/. Revitalized/verb Classics/noun Take/verb the/det Stage/noun in/adp Windy/noun City/noun ,/. ''/. Leisure/noun &/conj Arts/noun )/. ,/. the/det role/noun of/adp Celimene/noun ,/. played/verb by/adp Kim/noun Cattrall/noun ,/. was/verb mistakenly/adv attributed/verb to/prt Christina/noun Haag/noun ./. "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure accuracy in the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T14:43:06.277101Z",
     "start_time": "2020-04-21T14:43:06.252822Z"
    }
   },
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-21T14:43:06.453Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3517/5000 [00:37<00:13, 108.22it/s]"
     ]
    }
   ],
   "source": [
    "Y_hat = []\n",
    "for x in tqdm.tqdm(X):\n",
    "    Y_hat.append(hmm.predict_labels(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-21T14:43:06.645Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total   = 0\n",
    "for y,y_hat in zip(Y,Y_hat):\n",
    "    for y_hat_k, y_k in zip(y,y_hat):\n",
    "        total +=1\n",
    "        if y_hat_k == y_k:\n",
    "            correct +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-21T14:43:07.047Z"
    }
   },
   "outputs": [],
   "source": [
    "correct, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-21T14:43:07.261Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy posterior decode train data\", correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure accuracy in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-21T14:43:07.812Z"
    }
   },
   "outputs": [],
   "source": [
    "len(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-21T14:43:08.015Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = []\n",
    "Y_test = []\n",
    "for i in range(len(test_seq)):\n",
    "    xy = train_seq[i]\n",
    "    X_test.append([ind_to_word[x_i] for x_i in xy.x])\n",
    "    Y_test.append([ind_to_state[y_i] for y_i in xy.y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-21T14:43:08.217Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_test_hat = []\n",
    "for x in tqdm.tqdm(X_test):\n",
    "    Y_test_hat.append(hmm.predict_labels(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-21T14:43:08.746Z"
    }
   },
   "outputs": [],
   "source": [
    "correct_test = 0\n",
    "total_test   = 0\n",
    "for y,y_hat in zip(Y_test,Y_test_hat):\n",
    "    for y_hat_k, y_k in zip(y,y_hat):\n",
    "        total_test +=1\n",
    "        if y_hat_k == y_k:\n",
    "            correct_test +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-21T14:43:09.513Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy posterior decode test data\", correct_test/total_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "281.3858642578125px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
